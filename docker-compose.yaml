version: '3.8'

services:
  spark-master:
    build: ./
    image: da-spark-image
    entrypoint: ['./entrypoint.sh', 'master']
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9090" ]
      interval: 5s
      timeout: 3s
      retries: 3
    volumes:
      - ./data:/opt/spark/data
      - ./spark_apps:/opt/spark/apps
      - ./spark-logs:/opt/spark/spark-events
    ports:
      - '9090:9090'
      - '7077:7077'
    environment:
      - SPARK_LOCAL_IP=spark-master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/opt/spark/spark-events
      - SPARK_EVENTLOG_ENABLED=true
      - SPARK_EVENTLOG_DIR=/opt/spark/spark-events
      - SPARK_NO_DAEMONIZE=true

  jupyterlab:
      image: jupyter/pyspark-notebook:spark-3.3.1
      ports:
        - "8900:8888"  # JupyterLab
      volumes:
        - ./data:/home/jovyan/data  # Mount a local directory to the container for persistent storage
        - ./notebooks:/home/jovyan/work

  spark-history-server:
    image: da-spark-image
    entrypoint: ['./entrypoint.sh', 'history']
    depends_on:
      - spark-master
    env_file:
      - .env.spark
    volumes:
      - ./spark-logs:/opt/spark/spark-events
    ports:
      - '18080:18080'

  spark-worker:
#    container_name: da-spark-worker
    image: da-spark-image
    entrypoint: ['./entrypoint.sh', 'worker']
    depends_on:
      - spark-master
    env_file:
      - .env.spark
    volumes:
      - ./data:/opt/spark/data
      - ./spark_apps:/opt/spark/apps
      - ./spark-logs:/opt/spark/spark-events

volumes:
  spark-logs:
